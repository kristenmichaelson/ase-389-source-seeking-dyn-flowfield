<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>ASE-389</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />

        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

        <script type="text/javascript" src="https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js"> </script>

    </head>
    <body>
        <!-- Responsive navbar-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="#"> ASE-389 Modelling Multi-Agent Systems </a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                <div class="collapse navbar-collapse" id="navbarSupportedContent">
                    <ul class="navbar-nav ms-auto mb-2 mb-lg-0">
                        <li class="nav-item"><a class="nav-link active" aria-current="page" href="#">Final Report</a></li>
                        <!-- <li class="nav-item"><a class="nav-link" href="#">Milestone</a></li> -->
                        <!-- <li class="nav-item"><a class="nav-link" href="#">Final Report</a></li> -->
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Page content-->
        <div class="container">
            <div class="text-center mt-5">
                <h2> Multi-Robot Source Seeking in Dynamical Flowfield: A Game Theoretic Approach</h2>
                <p class="lead">Hassan Iqbal , Kristen Michaelson , Abayomi Adekanmbi </p>
            </div>
            <h4> Abstract</h4>  
                <p>This paper presents a distributed hybrid controller for solving online source seeking problem in a
                   dynamical environment. By formulating the problem as a multiple pursuer multiple evaders game, we simultaneously addresses 
                   the problem of discrete assignment of mobile robots to sources as well as the continuous controls strategies for capturing 
                   individual sources of external dynamic flow-field. </p>

                   

            <h4> Introduction</h4>  
                <p>Source-seeking, sometimes referred as extremum-seeking, involves locating and tracking one or multiple spots, associated with the maximum or minimum value of interest, in a possibly dynamical environment. 
                    It has been applied in surveillance, environment monitoring, disaster response etc. 
                    For example, consider the scenario where a contamination is introduced in a water body or air through submarines or air-borne drones respectively. 
                    Localizing and tracking all sources of contamination as soon as possible can play a crucial role in disseminating early warning as well as in coming up with localized corrective strategies. 
                    In this paper, we are assuming that the external flow-field is dynamically changing. Under such circumstances, the mobile robots need to collaboratively assign tasks to each other and localize all the moving sources.  

                    We formulate the problem of dynamical source seeking as a multiple pursuer multiple evader (MPME) game where identical pursuers represent mobile robots and evaders represent the sources moving passively in a dynamical flow field $$V_f(z,t)$$. 
                    For this work, we assume all the pursuers know positions of evaders. We further assume that pursuers can talk only to their neighbors. 
                    We also assume all players know the external dynamic flow field. The kinodynamic constraints of pursuer \textit{i} denoted by $$x_i(t)$$ are given as:


<!--                  
                \begin{figure}
                    \centering
                    \includegraphics[width=0.4\textwidth]{/assets/MMAS Figure.png}
                    \caption{Time evolution of the game}
                    \label{fig:MMAS Figure}
                \end{figure} -->


                \begin{equation}
                    \dot{x}_i = u_i(t) + {V_f}(z,t)
                    \label{eq:1}
                \end{equation}

            where $u_i(t)$ is the control vector. We say that pursuer \textit{i} can capture evader \textit{k}, denoted by $y_k(t)$ when 

            \begin{equation}
                x_i(t) \in \beta_r(y_k(t)) = {||x-y_k(t)||_2 < r}
                \label{eq:2}
            \end{equation}

where $\beta_r(y_k(t))$ is open ball of radius r centered at evader $\textit{k}$. Then our problem formulates to as follows:

Given \textit{n} identical pursuers and evaders and no prior assignment information, derive distributed control laws for every pursuer 
\textit{i} such that for any initial configuration $x_i(t_0)$, there exists a $T>0$ such that $x_i(t) \in \beta_r(y_k(t))$ for all time $t>t_0+T$, all pursuers \textit{i} and evaders \textit{k}.


<figure>
    <center><img src="assets/MMAS Figure.png" alt="Simulation" style="width:70%"> </center>
    <!--figcaption>Results</figcaption-->
</figure>


</p>

<h4>Specific Aim</h4> 

     <p>   We first aim to replicate the results presented in \cite{b4}, \textit{Distributed Hybrid Control for Multiple-Pursuer Multiple-Evader Games}. We will begin with equal numbers of pursuers and evaders (although \cite{b4} also extends to a formulation with more evaders than pursuers). In this work, both the pursuers' and evaders' dynamics are simple motion. The pursuers' control inputs $u_i$ are velocity vectors. The evaders do not strategize; instead, they follow pre-defined trajectories. Fig.\ref{fig:MMAS Figure} shows the time-evolution of a game with 7 players. 

        The pursuers start off gathered in one area. Meanwhile, the evaders begin to move in a circle. Eventually, the pursuers capture all the evaders.

        At every time step, each pursuer $x_i$ ``claims" the evader $y_k$ closest to it. Define $\gamma(x_i, y_k) = ||x_i - y_k||_2$ and $r(t) = Re^{-a(t - t_0)}$. The pursuer plans a trajectory based on the following strategy
        \begin{equation}
            \dot{x}_i = u_{R,a}(x_i, y_k, t) := -K\nabla\varphi_{R,a}(x_i, y_k, t)
            \label{eq:3}
        \end{equation}
        where $\varphi_{R,a}(x_i, y_k, t)$ is a potential function defined as $\varphi_{R,a}(x_i, y_k, t) = \frac{1}{r^2(t) - \gamma^2(x_i, y_k)}$. 

        We aim to replicate their online task assignment policy; making sure all evaders are pursued. Next, we aim to extend \cite{b4} to a game scenario in a dynamic flow field. The flow field will be known to the pursuers, and a new mapping from states to strategies (eq. \ref{eq:3}) will be developed based on this new information structure. Fig. \ref{fig:MMAS Figure} was adapted from \cite{b4} to demonstrate how this might look. 

        Additional possible extensions include:
        \begin{enumerate}
            \item Pursuers must estimate the flow field.
            \item Pursuers must estimation positions of evaders at each time steps.
            \item Smarter evaders with knowledge of pursuers strategies maximizing their cost and making capture difficult for the pursuers.
        \end{enumerate}

    </p>

    <h4>Technical Approach</h4> 
    <p>The pursuer strategy is defined in equation \ref{eq:3}. 
        Evaluating the gradient term, we have
        \begin{equation} 
            v_x = - 2K \frac{1}{\beta^2}(p_x - e_x) 
        \end{equation}
        \begin{equation} 
            v_y = - 2K \frac{1}{\beta^2}(p_y - e_y)
        \end{equation}

    The $\beta^2$ term in the denominator makes things tricky. 
    It can cause poor behavior if the constants $a$, $R$, and $K$ are not tuned appropriately.
    In the results presented here, $a$, $R$, and $K$ are tuned specifically for the task assignment algorithm defined in Zavlanos and Pappas (2007). 
    
    <h5>Hungarian Algorithm</h5>
    <p > For finding the initial assignment that minimizes the pair wise distance between evaders and pursuers. we used a version
    of the Hungarian algorithm. To that end we solved a linear assignment problem by constructing a cost matrix based on the distance between pursers and evader.
    We simulated result with both the dynamic flow field and without. 
   </p>
  
    <h5>Time to Capture Minimization</h5> 
    <p>
        Similar to the procedure in the hungarian method we implemented cost matrix based on the time to capture.
    </p>


<h4>Results</h4> 

    <p>Each of the three task assignment strategies was executed 10 times without a flow field and 10 times in a circular flow field.
       At the beginning of each trial, the pursuers are placed in random locations in a 1x1 m box at the bottom left of the screen. 
       The evaders always start in the same position. 
       When the flow field is off, the evaders move in a circle. 
       When the flow field is on, the evaders are placed in the flow field. The pursuers must "fight" against the flow field to capture the evaders. This increases time to capture. 
       Pursuer-evader assignments are computed at each time step. Pursuers may maintain the same target, or be assigned a new one.
       In the case of Zavlanos task assignment, they may remain unassigned for a few time steps at the beginning of the game. 
    </p>

    <p>The table below summarizes the performance of each task assignment algorithm. 
        The time given is the average of all the successful trials.
        A trial was considered to have failed if capture was not achieved by 30 s. 
    </p>

    <figure>
        <img src="assets/results.PNG" alt="results" style="width:100%">
        <!--figcaption>Results</figcaption-->
    </figure>

    <p>It is important to note that reported time is time steps (dt = 0.01), not CPU time. 
        Some task assignment algorithms likely take longer to run than others. 
        That said, the strategies were remarkably consistent (mean = median = mode), even with random pursuer starting positions.
    </p>


    <p><a href= "https://github.com/kristenmichaelson/ase-389-source-seeking-dyn-flowfield">Code implementation can be found here</p>

    
       
            <h3>References</h3>
             <p><a href="https://arxiv.org/pdf/2103.15660.pdf">Pursuer Assignment and Control Strategies in Multi-agent Pursuit-Evasion, Zhang, Prorok and Bhattacharya, 2021.</a></p>
             <p><a href="http://dcsl.gatech.edu/papers/jgcd16%20(Printed).pdf"> Multiple-pursuer/one-evader pursuit-evasion game in dynamic flowfields, Sun, Tsiotras, Lolla, Subramani, and Lermusiaux, 2017.
            </a></p>
             <p><a href="https://arxiv.org/pdf/2103.11016.pdf"> Multi-agent on-line extremum seeking using bandit algorithm, Du, Qian, Claudel and Sun, 2021.
            </a> </p>
            <p><a href="https://people.duke.edu/~mz61/papers/2007HSCC_Zavlanos_PursuerEvaderGames_Extended.pdf"> Distributed hybrid control for multiple-pursuer multiple-evader games,Zavlanos and Pappas, 2007. </a></p>



            
            <h4>Video</h4>
                <div align="center">
                       <!-- <iframe width="640" height="400" src="" frameborder="0" allowfullscreen/> -->
                       <iframe width="560" height="315" src="https://www.youtube.com/embed/hy1B8wpOd58" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

                   </div>


            </div>
          
              
        </div>

        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
